{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "other-fossil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (2.3.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.8.1)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy) (7.4.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy) (49.6.0.post20210108)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.56.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Collecting en_core_web_sm==2.3.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.0 MB 437 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.6.0.post20210108)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.25.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.56.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.4.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.12.5)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "helpful-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import json\n",
    "from string import punctuation\n",
    "import spacy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "collectible-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_test_object = {\n",
    "    \"name\": \"multiple_speakers_punctuation_v4.txt\",\n",
    "    \"bucket\": \"meeting-transcript-team13\",\n",
    "}\n",
    "\n",
    "# In Cloud Function set these as environment variables\n",
    "os.environ[\"KEYWORD\"] = \"Christina\"\n",
    "os.environ[\"SENTENCES_BEFORE\"] = \"2\"\n",
    "os.environ[\"SENTENCES_AFTER\"] = \"2\"\n",
    "os.environ[\"DST_BUCKET_NAME\"] = \"meeting-transcript-processed-team13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frequent-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_from_gcs(storage_client, src_bucket_name: str, src_filename: str):\n",
    "    \n",
    "    bucket = storage_client.get_bucket(src_bucket_name)\n",
    "    blob = bucket.blob(src_filename)\n",
    "    \n",
    "    # Download the contents of the blob as a bytes object\n",
    "    data = blob.download_as_string(client=None)\n",
    "    \n",
    "    print(f'Loaded {src_filename} from {src_bucket_name}')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alleged-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_from_transcript(bytes_object):\n",
    "    # Decode bytes object to string and remove new lines\n",
    "    transcript = bytes_object.decode('utf-8').replace('\\n', '')\n",
    "    \n",
    "    # Load spacy model package \"en_core_web_sm\"\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    # Read sentences as strings into list\n",
    "    about_transcript = nlp(transcript)\n",
    "    sentences = [sent.text for sent in about_transcript.sents]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "systematic-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(data, keyword: str, ind_before: int, ind_after: int):\n",
    "    \n",
    "    transcript_list = get_sentences_from_transcript(data)\n",
    "    \n",
    "    # Return list of indices containing name parameter\n",
    "    indices = [i for i, s in enumerate(transcript_list) if keyword in s]\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    for ind in indices:\n",
    "        min_ind = ind - ind_before\n",
    "        max_ind = ind + ind_after\n",
    "        sentences.append(transcript_list[min_ind:max_ind])\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interesting-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_gcs(storage_client, src_filepath: str, dst_bucket_name: str, dst_filename: str):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    \n",
    "    bucket = storage_client.get_bucket(dst_bucket_name)\n",
    "    \n",
    "    blob = bucket.blob(dst_filename)\n",
    "\n",
    "    blob.upload_from_filename(src_filepath)\n",
    "\n",
    "    return print(f'{src_filepath} uploaded to {dst_bucket_name}/{dst_filename}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "international-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_transcript_to_gcs(src_filename: str, \n",
    "                             transcript_number: int, \n",
    "                             transcript_list: list, \n",
    "                             title: str,\n",
    "                             storage_client, \n",
    "                             dst_bucket_name: str):\n",
    "    \"\"\"\"\"\"\n",
    "    dst_filename = os.path.join(\"PROCESSED_\" + src_filename.replace('.txt', f'_{transcript_number}.json'))\n",
    "    \n",
    "    tmp_filepath = os.path.join(\"/tmp\", dst_filename)\n",
    "\n",
    "    with open(f'{tmp_filepath}', 'w') as f:\n",
    "        json.dump({'title': title, 'message_body': transcript_list}, f)\n",
    "            \n",
    "    print(f'Processed transcript stored in: {tmp_filepath}')\n",
    "    \n",
    "    return upload_file_to_gcs(storage_client, tmp_filepath, dst_bucket_name, dst_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ranking-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_title(processed_transcript: str, keyword: str):\n",
    "    \"\"\"Creates a relevant title for the alert depending on whether a question was asked to the user.\"\"\"\n",
    "    if '?' in ''.join(processed_transcript):\n",
    "        return f'{keyword}, you have been asked a question'\n",
    "    else:\n",
    "        return f'{keyword}, your name has been mentioned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "contained-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcripts(data, context = None):\n",
    "    \n",
    "    # Set up parameters\n",
    "    KEYWORD = os.environ.get('KEYWORD')\n",
    "    SENTENCES_BEFORE = int(os.environ.get('SENTENCES_BEFORE'))\n",
    "    SENTENCES_AFTER = int(os.environ.get('SENTENCES_AFTER'))\n",
    "    FILE = data['name']\n",
    "    SRC_BUCKET_NAME = data['bucket']\n",
    "    DST_BUCKET_NAME = os.environ.get('DST_BUCKET_NAME')\n",
    "    \n",
    "    print(f'Source Bucket: {SRC_BUCKET_NAME}')\n",
    "    print(f'Source Filename: {FILE}')\n",
    "    print(f'Destination Bucket: {DST_BUCKET_NAME}')   \n",
    "    \n",
    "    print('Starting Process Transcript...')\n",
    "    \n",
    "    # Instantiate a Google Cloud Storage client and specify required bucket and file\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    # Get data from gcs\n",
    "    transcript = load_file_from_gcs(storage_client, SRC_BUCKET_NAME, FILE)\n",
    "    \n",
    "    # Process data\n",
    "    processed_transcript_list = get_sentences(transcript, KEYWORD, SENTENCES_BEFORE, SENTENCES_AFTER) \n",
    "\n",
    "    if len(processed_transcript_list) > 0:\n",
    "        # Upload data to gcs\n",
    "        for transcript_number, processed_transcript in enumerate(processed_transcript_list):\n",
    "            title = create_title(processed_transcript, KEYWORD)\n",
    "            upload_transcript_to_gcs(FILE, transcript_number, processed_transcript, title, storage_client, DST_BUCKET_NAME)\n",
    "    else:\n",
    "        print('No instance of keyword found.')\n",
    "    \n",
    "    print('Process Transcript Complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "complicated-referral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Bucket: meeting-transcript-team13\n",
      "Source Filename: multiple_speakers_punctuation_v4.txt\n",
      "Destination Bucket: meeting-transcript-processed-team13\n",
      "Starting Process Transcript...\n",
      "Loaded multiple_speakers_punctuation_v4.txt from meeting-transcript-team13\n",
      "Processed transcript stored in: /tmp/PROCESSED_multiple_speakers_punctuation_v4_0.json\n",
      "/tmp/PROCESSED_multiple_speakers_punctuation_v4_0.json uploaded to meeting-transcript-processed-team13/PROCESSED_multiple_speakers_punctuation_v4_0.json.\n",
      "Processed transcript stored in: /tmp/PROCESSED_multiple_speakers_punctuation_v4_1.json\n",
      "/tmp/PROCESSED_multiple_speakers_punctuation_v4_1.json uploaded to meeting-transcript-processed-team13/PROCESSED_multiple_speakers_punctuation_v4_1.json.\n",
      "Processed transcript stored in: /tmp/PROCESSED_multiple_speakers_punctuation_v4_2.json\n",
      "/tmp/PROCESSED_multiple_speakers_punctuation_v4_2.json uploaded to meeting-transcript-processed-team13/PROCESSED_multiple_speakers_punctuation_v4_2.json.\n",
      "Processed transcript stored in: /tmp/PROCESSED_multiple_speakers_punctuation_v4_3.json\n",
      "/tmp/PROCESSED_multiple_speakers_punctuation_v4_3.json uploaded to meeting-transcript-processed-team13/PROCESSED_multiple_speakers_punctuation_v4_3.json.\n",
      "Processed transcript stored in: /tmp/PROCESSED_multiple_speakers_punctuation_v4_4.json\n",
      "/tmp/PROCESSED_multiple_speakers_punctuation_v4_4.json uploaded to meeting-transcript-processed-team13/PROCESSED_multiple_speakers_punctuation_v4_4.json.\n",
      "Processed transcript stored in: /tmp/PROCESSED_multiple_speakers_punctuation_v4_5.json\n",
      "/tmp/PROCESSED_multiple_speakers_punctuation_v4_5.json uploaded to meeting-transcript-processed-team13/PROCESSED_multiple_speakers_punctuation_v4_5.json.\n",
      "Processed transcript stored in: /tmp/PROCESSED_multiple_speakers_punctuation_v4_6.json\n",
      "/tmp/PROCESSED_multiple_speakers_punctuation_v4_6.json uploaded to meeting-transcript-processed-team13/PROCESSED_multiple_speakers_punctuation_v4_6.json.\n",
      "Processed transcript stored in: /tmp/PROCESSED_multiple_speakers_punctuation_v4_7.json\n",
      "/tmp/PROCESSED_multiple_speakers_punctuation_v4_7.json uploaded to meeting-transcript-processed-team13/PROCESSED_multiple_speakers_punctuation_v4_7.json.\n",
      "Processed transcript stored in: /tmp/PROCESSED_multiple_speakers_punctuation_v4_8.json\n",
      "/tmp/PROCESSED_multiple_speakers_punctuation_v4_8.json uploaded to meeting-transcript-processed-team13/PROCESSED_multiple_speakers_punctuation_v4_8.json.\n",
      "Process Transcript Complete.\n"
     ]
    }
   ],
   "source": [
    "process_transcripts(gcs_test_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-wilson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
